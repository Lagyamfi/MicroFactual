{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88de76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from microbiome_ml.data_processing import load_data, filter_data, clr_transform\n",
    "from microbiome_ml.modeling import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9fa344",
   "metadata": {},
   "outputs": [],
   "source": [
    "abundance_path = \"../Dataset/abundance_crc.txt\"\n",
    "metadata_path = \"../Dataset/metadata_crc.txt\"\n",
    "target_column = \"Group\"\n",
    "abundance, labels = load_data(abundance_file=abundance_path, metadata_file=metadata_path, target_column=target_column)\n",
    "filtered_data = filter_data(abundance)\n",
    "clr_data = clr_transform(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49583711",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(clr_data, labels, n_jobs=1)\n",
    "clr_data['target'] = labels.values\n",
    "dataset = clr_data\n",
    "target = dataset['target']\n",
    "train_dataset, test_dataset, _, _ = train_test_split(dataset,\n",
    "                                                     target,\n",
    "                                                     test_size=0.2,\n",
    "                                                     random_state=0,\n",
    "                                                     stratify=target)\n",
    "# model = LogisticRegression()\n",
    "# model.fit(train_dataset.drop(columns=\"target\"), train_dataset[\"target\"])\n",
    "\n",
    "# Dataset for training an ML model\n",
    "d = dice_ml.Data(dataframe=train_dataset,\n",
    "                 continuous_features=dataset.columns[:-1].tolist(),\n",
    "                 outcome_name='target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4ce1ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- target\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m queries = test_dataset[test_dataset[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[32m1\u001b[39m].drop(columns=\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m query_instance = queries[\u001b[32m0\u001b[39m:\u001b[32m1\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m dice_exp = \u001b[43mexp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_counterfactuals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_CFs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_class\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopposite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Visualize counterfactual explanation\u001b[39;00m\n\u001b[32m     11\u001b[39m dice_exp.visualize_as_dataframe(show_only_changes=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PERSONAL/PROJECTS/ML_Microbiome_Package/.venv/lib/python3.13/site-packages/dice_ml/explainer_interfaces/explainer_base.py:161\u001b[39m, in \u001b[36mExplainerBase.generate_counterfactuals\u001b[39m\u001b[34m(self, query_instances, total_CFs, desired_class, desired_range, permitted_range, features_to_vary, stopping_threshold, posthoc_sparsity_param, proximity_weight, sparsity_weight, diversity_weight, categorical_penalty, posthoc_sparsity_algorithm, verbose, **kwargs)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m query_instance \u001b[38;5;129;01min\u001b[39;00m tqdm(query_instances_list):\n\u001b[32m    160\u001b[39m     \u001b[38;5;28mself\u001b[39m.data_interface.set_continuous_feature_indexes(query_instance)\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_counterfactuals\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_CFs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesired_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdesired_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesired_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdesired_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpermitted_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpermitted_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeatures_to_vary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures_to_vary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposthoc_sparsity_param\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposthoc_sparsity_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposthoc_sparsity_algorithm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposthoc_sparsity_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    172\u001b[39m     cf_examples_arr.append(res)\n\u001b[32m    173\u001b[39m \u001b[38;5;28mself\u001b[39m._check_any_counterfactuals_computed(cf_examples_arr=cf_examples_arr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PERSONAL/PROJECTS/ML_Microbiome_Package/.venv/lib/python3.13/site-packages/dice_ml/explainer_interfaces/dice_genetic.py:270\u001b[39m, in \u001b[36mDiceGenetic._generate_counterfactuals\u001b[39m\u001b[34m(self, query_instance, total_CFs, initialization, desired_range, desired_class, proximity_weight, sparsity_weight, diversity_weight, categorical_penalty, algorithm, features_to_vary, permitted_range, yloss_type, diversity_loss_type, feature_weights, stopping_threshold, posthoc_sparsity_param, posthoc_sparsity_algorithm, maxiterations, thresh, verbose)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28mself\u001b[39m.num_output_nodes = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.model_type == ModelTypes.Classifier:\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28mself\u001b[39m.num_output_nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_num_output_nodes2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_instance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m query_instance = \u001b[38;5;28mself\u001b[39m.label_encode(query_instance)\n\u001b[32m    273\u001b[39m query_instance = np.array(query_instance.values[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PERSONAL/PROJECTS/ML_Microbiome_Package/.venv/lib/python3.13/site-packages/dice_ml/model_interfaces/base_model.py:70\u001b[39m, in \u001b[36mBaseModel.get_num_output_nodes2\u001b[39m\u001b[34m(self, input_instance)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == ModelTypes.Regressor:\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SystemException(\u001b[33m'\u001b[39m\u001b[33mNumber of output nodes not supported for regression\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_instance\u001b[49m\u001b[43m)\u001b[49m.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PERSONAL/PROJECTS/ML_Microbiome_Package/.venv/lib/python3.13/site-packages/dice_ml/model_interfaces/base_model.py:54\u001b[39m, in \u001b[36mBaseModel.get_output\u001b[39m\u001b[34m(self, input_instance, model_score)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_score:\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == ModelTypes.Classifier:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_instance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     56\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.predict(input_instance)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PERSONAL/PROJECTS/ML_Microbiome_Package/.venv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:621\u001b[39m, in \u001b[36mBaseSearchCV.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    602\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Call predict_proba on the estimator with the best found parameters.\u001b[39;00m\n\u001b[32m    603\u001b[39m \n\u001b[32m    604\u001b[39m \u001b[33;03mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    618\u001b[39m \u001b[33;03m    to that in the fitted attribute :term:`classes_`.\u001b[39;00m\n\u001b[32m    619\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    620\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbest_estimator_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PERSONAL/PROJECTS/ML_Microbiome_Package/.venv/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:946\u001b[39m, in \u001b[36mForestClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    944\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[32m    949\u001b[39m n_jobs, _, _ = _partition_estimators(\u001b[38;5;28mself\u001b[39m.n_estimators, \u001b[38;5;28mself\u001b[39m.n_jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PERSONAL/PROJECTS/ML_Microbiome_Package/.venv/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:638\u001b[39m, in \u001b[36mBaseForest._validate_X_predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    636\u001b[39m     ensure_all_finite = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X.indices.dtype != np.intc \u001b[38;5;129;01mor\u001b[39;00m X.indptr.dtype != np.intc):\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PERSONAL/PROJECTS/ML_Microbiome_Package/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2919\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2836\u001b[39m     _estimator,\n\u001b[32m   2837\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2843\u001b[39m     **check_params,\n\u001b[32m   2844\u001b[39m ):\n\u001b[32m   2845\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2846\u001b[39m \n\u001b[32m   2847\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2917\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2918\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2920\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/PERSONAL/PROJECTS/ML_Microbiome_Package/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2777\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2775\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2777\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- target\n"
     ]
    }
   ],
   "source": [
    "# Pre-trained ML model\n",
    "m = dice_ml.Model(model=model,\n",
    "                  backend='sklearn')\n",
    "# DiCE explanation instance\n",
    "exp = dice_ml.Dice(d,m, method=\"genetic\")\n",
    "# Generate counterfactual examples\n",
    "queries = test_dataset[test_dataset[\"target\"] == 1].drop(columns=\"target\")\n",
    "query_instance = queries[0:1]\n",
    "dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=5, desired_class=\"opposite\", verbose=True)\n",
    "# Visualize counterfactual explanation\n",
    "dice_exp.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822e148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
